{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e6e453aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from context import Context\n",
    "from models import ModifiedNet\n",
    "import helpers as h\n",
    "import constants as const\n",
    "from data_tools import DTI_DATA_TOOL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7bc5a06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(file_name = \"model.pickle\"):\n",
    "    try:\n",
    "        device,_ = h.check_device()\n",
    "        model_dict = torch.load(file_name,map_location=torch.device('cpu'))\n",
    "        CTX = model_dict['context']\n",
    "        CTX.device = device\n",
    "        W_dict = model_dict['model']\n",
    "        NET = ModifiedNet(CTX).to(CTX.device)\n",
    "        NET.load_state_dict(W_dict)\n",
    "        return NET, CTX\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load model with following error:\\n{e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7409dc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HALT! Kinase information could not be read\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Failed to load intermediate files.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j0/_67sb4v12ms1_0v71ytghd480000gn/T/ipykernel_70995/4502535.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mDATA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDTI_DATA_TOOL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_intermediate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTERMEDIATE_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCTX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mDATA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_and_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mNET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCTX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model048132012.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mNET\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/MAIN/THESIS/CODE_vol15/MODELS/data_tools/data_tools.py\u001b[0m in \u001b[0;36mload_and_prepare\u001b[0;34m(self, src_smiles, src_target, src_fps, src_int_train, src_int_test1, src_int_test2)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_from_intermediates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0;32mraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to load intermediate files.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;31m########################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Failed to load intermediate files."
     ]
    }
   ],
   "source": [
    "DATA = DTI_DATA_TOOL(src_intermediate=const.INTERMEDIATE_DIR, src_data=const.DATA_DIR, device = CTX.device)\n",
    "DATA.load_and_prepare()\n",
    "\n",
    "NET, CTX = load_model(\"model048132012.pickle\")\n",
    "NET.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    X_validation = DATA.validation_batch()\n",
    "    X_test1 = DATA.prepare_test_batch(0)\n",
    "    X_test2 = DATA.prepare_test_batch(1)\n",
    "\n",
    "    # PREDICTIONS\n",
    "    pred_validation = NET.forward(X_validation[0:4])\n",
    "    pred_test1 = NET.forward(X_test1[0:4])\n",
    "    pred_test2 = NET.forward(X_test2[0:4])\n",
    "\n",
    "    # SET TRESHOLD TO = 5\n",
    "    pred_validation[pred_validation<5]=5\n",
    "    pred_test1[pred_test1<5]=5\n",
    "    pred_test2[pred_test2<5]=5\n",
    "\n",
    "    # TRUE VALUES\n",
    "    true_validation = X_validation[4]\n",
    "    true_test1 = torch.unsqueeze(X_test1[4], 1)\n",
    "    true_test2 = torch.unsqueeze(X_test2[4], 1)\n",
    "\n",
    "    # RMSE-ERRORS \n",
    "    e_v = torch.sqrt( const.CRITERION(pred_validation,true_validation) ).cpu()\n",
    "    e_1 = torch.sqrt( const.CRITERION(pred_test1,true_test1) ).cpu()\n",
    "    e_2 = torch.sqrt( const.CRITERION(pred_test2,true_test2) ).cpu()\n",
    "\n",
    "# PEARSON CORRELATION\n",
    "s_v = stats.spearmanr(pred_validation.cpu().detach().numpy(), X_validation[4].cpu())[0]\n",
    "s_1 = stats.spearmanr(pred_test1.cpu().detach().numpy(), X_test1[4].cpu())[0]\n",
    "s_2 = stats.spearmanr(pred_test2.cpu().detach().numpy(), X_test2[4].cpu())[0]\n",
    "\n",
    "errorv = torch.tensor(true_validation-pred_validation).cpu()\n",
    "error1 = torch.tensor(true_test1-pred_test1).cpu()\n",
    "has_family1 = [['red','green'][int(torch.sum(f)!= 0) ] for f in X_test1[3]]\n",
    "error2 = torch.tensor(true_test2-pred_test2).cpu()\n",
    "has_family2 = [['red','green'][int(torch.sum(f)!= 0) ] for f in X_test2[3]]\n",
    "\n",
    "fig = plt.figure(figsize=[8,12])\n",
    "#fig.suptitle('Results for {} epochs with parameters lr={}, bs={}, hs={}'.format(const.EPOCHS, self.params[0],self.params[1],self.params[2]), fontsize=16)\n",
    "ax0 = fig.add_subplot(3,1,1)\n",
    "ax0.set_title('Validation Set')\n",
    "ax0.scatter(true_validation.cpu(), errorv)\n",
    "ax0.text(8,-2.5,'RMSE={:.4f}\\nSPEARMAN={:.4f}'.format(e_v.item(),s_v ) )\n",
    "ax1 = fig.add_subplot(3,1,2)\n",
    "ax1.scatter(true_test1.cpu(), error1, c=has_family1)\n",
    "ax1.set_title('Test Set 1')\n",
    "ax1.text(8.5,-2.5,'RMSE={:.4f}\\nSPEARMAN={:.4f}'.format(e_1.item(),s_1 ) )\n",
    "ax2 = fig.add_subplot(3,1,3)\n",
    "ax2.scatter(true_test2.cpu(), error2, c=has_family2)\n",
    "ax2.set_title('Test Set 2')\n",
    "ax2.text(8.5,-2,'RMSE={:.4f}\\nSPEARMAN={:.4f}'.format(e_2.item(),s_2 ) )\n",
    "fig.savefig('test_errors.png')\n",
    "\n",
    "print(\"\\n VALIDATION SET:\\n ERROR = {}, SPEARMAN = {}\".format(e_v,s_v))\n",
    "print(\"\\n TEST SET 1:\\n ERROR = {}, SPEARMAN = {}\".format(e_1,s_1))\n",
    "print(\"\\n TEST SET 2:\\n ERROR = {}, SPEARMAN = {}\".format(e_2,s_2))\n",
    "\n",
    "result_df = pd.DataFrame.from_dict( {'error':[e_v,e_1,e_2],'spearman': [s_v,s_1,s_2]}, orient='index', columns=[\"Validation Set\", \"Test Set 1\", \"Test Set 2\"] )\n",
    "h.save_df_to_csv(result_df,const.RESULTS_DIR+'model_results.csv')\n",
    "NET.train()\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dface6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on the CPU\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe5b6f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
